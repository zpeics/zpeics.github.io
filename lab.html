
<!DOCTYPE html>

<html lang="en-US" xmlns="http://www.w3.org/1999/html">

  <head>

    <meta name="generator"

    content="HTML Tidy for HTML5 (experimental) for Windows https://github.com/w3c/tidy-html5/tree/c63cc39" />

    <title>智能视觉实验室</title>

    <!-- META TAGS -->

    <meta charset="UTF-8" />

    

    <!-- CSS FILES -->

    <link href="https://cdn.staticfile.org/twitter-bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet" />

    <link rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/3.3.7/css/bootstrap.min.css" />

    <link rel="stylesheet" href="css/bootstrap-responsive.css" type="text/css" />

    <script src="https://cdn.staticfile.org/jquery/2.1.1/jquery.min.js"></script>

    <script src="https://cdn.staticfile.org/twitter-bootstrap/3.3.7/js/bootstrap.min.js"></script>

  

    <link href="css/slick.css" rel="stylesheet" type="text/css" />

    <link href="css/style.css" rel="stylesheet" type="text/css" />

  </head>

  <body>

    <!-- 实验室简介 -->

    <progress value="0" id="eskimo-progress-bar"></progress>

    <div class="container">

      <img src="images/Peterlogo.png"  />

    <!--菜单栏详情-->

      <nav class="navbar navbar-default" role="navigation">

        <ul class="nav navbar-nav" id = "nav" style="font-weight:bold; color:blue;">

          <li>

            <a href="index.html"><span style="color: #2196F2; ">个人简介</span></a>

          </li>

          <li>

            <a href="lab.html"><span style="color: #2196F2; ">实验室</span></a>

          </li>

          <li>

            <a href="Result.html"><span style="color: #2196F2; ">研究成果</span></a>

          </li>

          <li>

            <a href="Course.html"><span style="color: #2196F2; ">授课</span></a>

          </li>

          <li>

            <a href="news.html"><span style="color: #2196F2; ">新闻动态</span></a>

          </li>



          <li>

            <a href="Contact.html"><span style="color: #2196F2; ">招生信息</span></a>

          </li>





        </ul>

      </nav>

	

	<hr class="simple" style="border:1px solid #2196F3;" />

	 <h1>实验室风采</h1>

    <div class="row">

      <div class="col-md-12">

        <div id="myCarousel" class="carousel slide pad_010 b_k" data-ride="carousel">

        <!-- 轮播（Carousel）指标 -->

        <ol class="carousel-indicators"></ol>

        <!-- 轮播（Carousel）项目 -->

        <div class="carousel-inner bor_btm">

          <div class="item active">

            <div class="pic row">

            <img class="col-xs-4 col-md-4 col-lg-4 " src="uploads/2018/05/list8.PNG" /> 

            <img class="col-xs-4 col-md-4 col-lg-4" src="uploads/2018/05/list2.jpg" /> 

            <img class="col-xs-4 col-md-4 col-lg-4" src="uploads/2018/05/list3.png" /></div>

          </div>

          <div class="item">

            <div class="pic row">

			<img class="col-xs-4 col-md-4 col-lg-4" src="uploads/2018/05/list4.jpg" /> 

            <img class="col-xs-4 col-md-4 col-lg-4" src="uploads/2018/05/list5.jpg" />

            <img class="col-xs-4 col-md-4 col-lg-4" src="uploads/2018/05/list6.png" />

            </div>

          </div>

        </div>

        <!-- 轮播（Carousel）导航 -->

        </div>

      </div>

    </div>

	<br>

    <div class="row">

      <div class="col-12 col-lg-12">

        <p>

        <strong>智能视觉实验室(SNNU-VISION)</strong>&nbsp;&nbsp;  本团队是一支来自陕西师范大学，怀揣着对计算机视觉和人工智能的狂热喜爱，富有理想和追求的一流研发团队。在陕西师范大学计算机科学学院裴炤教授的带领下，依托于现代教学技术教育部重点实验室，团队长期从事计算机视觉、深度学习等前沿基础理论和应用开发的研究, 承担了国家自然基金面上项目、国家自然基金青年项目、陕西省重点研发计划、陕西省自然科学基金等科学研究项目；在计算机视觉、图像处理、机器学习与人工智能研究领域，取得了一批有影响的研究成果。在计算机视觉与模式识别领域重要期刊TCSVT, PR等国内外刊物及国际会议上发表论文多篇。我们非常欢迎爱好计算机视觉与图像处理、人工智能和机器学习的同学前来加入我们的行列，攻读硕士或博士学位。</p>

      </div>

    </div>

    <!-- 在校生 -->

    <hr class="simple" style="border:1px solid #2196F3;" />

    <div>

      <h1>在校生</h1>

    </div>

    <div class="row">

		


			 

      <div class="col-xs-3 col-md-2 col-lg-2 text-center">
  
          <img class="img-circle img-responsive" src="uploads/2018/05/zhangwenwen.jpg" />
  
          <div class="member-despt">
          <span style="white-space:nowrap" >
            <b>张文文</b>
            <br>
  
            <p>师资博士后，2021级
  
        <b>&nbsp;</b>
  
  
        </p>
          </span>
          </div>
  
        </div>
  
  
  
          <!-- <div class="col-xs-3 col-md-2 col-lg-2 text-center">
  
          <img class="img-circle img-responsive" src="uploads/2018/05/ycl.png" />
  
          <div class="member-despt">
              <span style="white-space:nowrap" >
            <b>杨翠柳</b>
            <br>
            <b>行人轨迹预测</b>
  
            <p>研究生，2020级
  
  		  <br/>
  
  		  <b style="color:blue">优秀毕业研究生</b>
  
  
        <b>&nbsp;</b>
  
  
  
        </p>
              </span>
          </div>
  
        </div> -->
  
          <div class="col-xs-3 col-md-2 col-lg-2 text-center">
  
              <img class="img-circle img-responsive" src="uploads/2018/05/lyh.png" />
  
              <div class="member-despt">
              <span style="white-space:nowrap" >
                  <b>李依函</b>
  
                  <br>
                  <b>行为识别</b>
                  <p>研究生，2021级</p>
                  </span>
              </div>
  
          </div>
  
          <div class="col-xs-3 col-md-2 col-lg-2 text-center">
  
              <img class="img-circle img-responsive" src="uploads/2018/05/luyi.png" />
  
              <div class="member-despt">
              <span style="white-space:nowrap" >
                  <b>尹璐</b>
  
                  <br>
                  <b>&nbsp;</b>
                  <p>研究生，2021级</p>
                  </span>
              </div>
  
          </div>
          <div class="col-xs-3 col-md-2 col-lg-2 text-center">
  
            <img class="img-circle img-responsive" src="uploads/2018/05/zjq.jpg" />

            <div class="member-despt">
            <span style="white-space:nowrap" >
                <b>张家庆</b>

                <br>
                <b>&nbsp;</b>
                <p>研究生，2021级</p>
                </span>
            </div>

        </div>
        <div class="col-xs-3 col-md-2 col-lg-2 text-center">
  
          <img class="img-circle img-responsive" src="uploads/2018/05/xmf.jpg" />

          <div class="member-despt">
          <span style="white-space:nowrap" >
              <b>徐铭锋</b>

              <br>
              <b>&nbsp;</b>
              <p>研究生，2022级</p>
              </span>
          </div>

      </div>

      <div class="col-xs-3 col-md-2 col-lg-2 text-center">
  
        <img class="img-circle img-responsive" src="uploads/2018/05/xyf.jpg" />

        <div class="member-despt">
        <span style="white-space:nowrap" >
            <b>许远枋</b>

            <br>
            <b>&nbsp;</b>
            <p>研究生，2022级</p>
            </span>
        </div>

    </div>

    <div class="col-xs-3 col-md-2 col-lg-2 text-center">
  
      <img class="img-circle img-responsive" src="uploads/2018/05/xyn.jpg" />

      <div class="member-despt">
      <span style="white-space:nowrap" >
          <b>薛颜妮</b>

          <br>
          <b>&nbsp;</b>
          <p>研究生，2022级</p>
          </span>
      </div>

  </div>

  <!-- <div class="col-xs-3 col-md-2 col-lg-2 text-center">
  
    <img class="img-circle img-responsive" src="uploads/2018/05/zyx.png" />

    <div class="member-despt">
    <span style="white-space:nowrap" >
        <b>周彦辛</b>

        <br>
        <b>&nbsp;</b>
        <p>本科生，2019级</p>
        </span>
    </div>

</div>

<div class="col-xs-3 col-md-2 col-lg-2 text-center">
  
  <img class="img-circle img-responsive" src="uploads/2018/05/hgr.jpg" />

  <div class="member-despt">
  <span style="white-space:nowrap" >
      <b>胡耕瑞</b>

      <br>
      <b>&nbsp;</b>
      <p>本科生，2019级</p>
      </span>
  </div>

</div>

<div class="col-xs-3 col-md-2 col-lg-2 text-center">
  
  <img class="img-circle img-responsive" src="uploads/2018/05/lxw.png" />

  <div class="member-despt">
  <span style="white-space:nowrap" >
      <b>廖心为</b>

      <br>
      <b>&nbsp;</b>
      <p>本科生，2019级</p>
      </span>
  </div>

</div> -->

<div class="col-xs-3 col-md-2 col-lg-2 text-center">
  
  <img class="img-circle img-responsive" src="uploads/2018/05/zxc.jpg" />

  <div class="member-despt">
  <span style="white-space:nowrap" >
      <b>张笑晨</b>

      <br>
      <b>&nbsp;</b>
      <p>本科生，2020级</p>
      </span>
  </div>

</div>

<div class="col-xs-3 col-md-2 col-lg-2 text-center">
  
  <img class="img-circle img-responsive" src="uploads/2018/05/gxy.png" />

  <div class="member-despt">
  <span style="white-space:nowrap" >
      <b>郭心怡</b>

      <br>
      <b>&nbsp;</b>
      <p>本科生，2020级</p>
      </span>
  </div>

</div>

<div class="col-xs-3 col-md-2 col-lg-2 text-center">
  
  <img class="img-circle img-responsive" src="uploads/2018/05/shujin.png" />

  <div class="member-despt">
  <span style="white-space:nowrap" >
      <b>舒进</b>

      <br>
      <b>&nbsp;</b>
      <p>本科生，2020级</p>
      </span>
  </div>

</div>
<div class="col-xs-3 col-md-2 col-lg-2 text-center">
  
  <img class="img-circle img-responsive" src="uploads/2018/05/yyy.png" />

  <div class="member-despt">
  <span style="white-space:nowrap" >
      <b>周彦辛</b>

      <br>
      <b>&nbsp;</b>
      <p>本科生，2021级</p>
      </span>
  </div>
    </div>
    </div>


          
  
      
      
  
     
  
        
  
      
   

	<!-- 毕业生 -->

    

	<hr class="simple" style="border:1px solid #2196F3;" />

    <div>

      <h1>毕业生</h1>

    </div>



    <div class="row">

      </div>
      <div class="col-xs-3 col-md-2 col-lg-2 text-center">

        <img class="img-circle img-responsive" src="uploads/2018/05/ycl.png" />

        <div class="member-despt">
        <span style="white-space:nowrap" >
          <b>杨翠柳</b>

          <p>研究生，2023届

		  <br/>

		  <b style="color:blue">优秀毕业研究生</b>
      <br/>
		  <b style="color:blue">优秀研究生学位论文</b>

              <br/>就职于深圳思尔芯

			  <br/>

			<b>&nbsp;</b>


			</p>
        </span>
        </div>

      </div>

      <div class="col-xs-3 col-md-2 col-lg-2 text-center">
  
        <img class="img-circle img-responsive" src="uploads/2018/05/zyx.png" />
    
        <div class="member-despt">
        <span style="white-space:nowrap" >
            <b>周彦辛</b>
            <p>本科生，2023届

              <br />悉尼大学<br>攻读硕士学位
    
          <br/>
    
            <b>&nbsp;</b>
    
            <br/>
    
            <b>&nbsp;</b>	
    
          </p>
            </span>
        </div>
    
    </div>
    
    <div class="col-xs-3 col-md-2 col-lg-2 text-center">
      
      <img class="img-circle img-responsive" src="uploads/2018/05/hgr.jpg" />
    
      <div class="member-despt">
      <span style="white-space:nowrap" >
          <b>胡耕瑞</b>
          <p>本科生，2023届

            <br />陕西师范大学<br>攻读硕士学位
  
        <br/>
  
          <b>&nbsp;</b>
  
          <br/>
  
          <b>&nbsp;</b>	
  
        </p>
          </span>
      </div>
    
    </div>
    
    <div class="col-xs-3 col-md-2 col-lg-2 text-center">
      
      <img class="img-circle img-responsive" src="uploads/2018/05/lxw.png" />
    
      <div class="member-despt">
      <span style="white-space:nowrap" >
          <b>廖心为</b>
    
          <p>本科生，2023届

            <br />悉尼大学<br>攻读硕士学位
  
        <br/>
  
          <b>&nbsp;</b>
  
          <br/>
  
          <b>&nbsp;</b>	
  
        </p>
          </span>
      </div>
    
    </div>
	  <div class="col-xs-3 col-md-2 col-lg-2 text-center">

        <img class="img-circle img-responsive" src="uploads/2018/05/QWT.jpg" />

        <div class="member-despt">
        <span style="white-space:nowrap" >
          <b>邱文涛</b>

          <p>研究生，2022届

<!--		  <br/>-->

<!--		  <b style="color:blue">优秀毕业研究生</b>-->

              <br/>就职于北京<br><span style="white-space: nowrap">广联达科技股份<br>有限公司</span>

			  <br/>

			<b>&nbsp;</b>


			</p>
        </span>
        </div>

      </div>



        <div class="col-xs-3 col-md-2 col-lg-2 text-center">

        <img class="img-circle img-responsive" src="uploads/2018/05/gys3.png" />

        <div class="member-despt">
            <span style="white-space:nowrap" >
          <b>苟元帅</b>

          <p>研究生，2022届

<!--		  <br/>-->

<!--		  <b style="color:blue">优秀毕业研究生</b>-->

              <br/>就职于成都<br><span style="white-space: nowrap">亚控科技发展<br>有限公司</span>

			  <br/>

			<b>&nbsp;</b>



			</p>
            </span>
        </div>

      </div>

        <div class="col-xs-3 col-md-2 col-lg-2 text-center">

            <img class="img-circle img-responsive" src="uploads/2018/05/wzy.jpg" />

            <div class="member-despt">
            <span style="white-space:nowrap" >
                <b>万志杨</b>

                <p>本科生，2022届
                    <br>
                    <b style="color:blue">优秀毕业论文</b>

                    <!--		  <br/>-->

                    <!--		  <b style="color:blue">优秀毕业研究生</b>-->

                    <br/>就职于上海<br>哔哩哔哩科技<br>有限公司



                </p>
                </span>
            </div>

        </div>

        <div class="col-xs-3 col-md-2 col-lg-2 text-center">

            <img class="img-circle img-responsive" src="uploads/2018/05/mjl.jpg" />

            <div class="member-despt">
            <span style="white-space:nowrap" >
                <b>马金丽</b>

                <p>本科生，2022届

                    <!--		  <br/>-->

                    <!--		  <b style="color:blue">优秀毕业研究生</b>-->

                    <br/>保送至陕西师范大学<br>攻读硕士学位

                    <br/>

                    <b>&nbsp;</b>
                    <br/>
                    <b>&nbsp;</b>

                </p>
                </span>
            </div>

        </div>

        <div class="col-xs-3 col-md-2 col-lg-2 text-center">

        <img class="img-circle img-responsive" src="uploads/2018/05/jm.png" />

        <div class="member-despt">
        <span style="white-space:nowrap" >
          <b>金敏</b>

          <p>研究生，2021届

		  <br/>

		  <b style="color:blue">优秀毕业研究生</b>

		  <br/>就职于安徽电信

			  <br/>

			<b>&nbsp;</b>

			  <br/>

			<b>&nbsp;</b>

		  </p>
        </span>
        </div>

      </div>



	  <div class="col-xs-3 col-md-2 col-lg-2 text-center">

        <img class="img-circle img-responsive" src="uploads/2018/05/hl.png" />

        <div class="member-despt">
        <span style="white-space:nowrap" >
          <b>黄丽</b>

          <p>研究生，2020届

		  <br/>

		  <b style="color:blue">优秀毕业研究生</b>

		  <br/>北京交通大学<br>攻读博士学位

			<br/>

			  <b>&nbsp;</b>

		  </p>
        </span>
        </div>

      </div>

		

	 <div class="col-xs-3 col-md-2 col-lg-2 text-center">

        <img class="img-circle img-responsive" src="uploads/2018/05/tq.png" />

        <div class="member-despt">
        <span style="white-space:nowrap" >
          <b>田龙伟</b>

          <p>研究生，2020届

		  <br/>

		  <b style="color:blue">优秀毕业研究生</b>

            <br/><span style="white-space:nowrap;">就职于西安浦发银行</span>			  

			  <br/>

			<b>&nbsp;</b>

			  <br/>

			<b>&nbsp;</b>

			</p>
        </span>
        </div>

     </div>

		

	 <div class="col-xs-3 col-md-2 col-lg-2 text-center">

        <img class="img-circle img-responsive center-block" src="uploads/2018/05/QYP.jpg" />

        <div>
<span style="white-space:nowrap" >
          <b>彭其阳</b>

          <p>本科生，2020届

		  <br/>

		  <b style="color:blue">优秀本科毕业生</b>

		  <br />保送至中山大学<br>攻读硕士学位

			  <br/>

			<b>&nbsp;</b>

			</p>
</span>
        </div>

     </div>

		

     <div class="col-xs-3 col-md-2 col-lg-2 text-center">

        <img class="img-circle img-responsive center-block" src="uploads/2018/05/wdq.jpg" />

        <div class="member-despt">
<span style="white-space:nowrap" >
          <b>汶得强</b>

          <p>本科生，2020届

		  <br/>

		  <b style="color:blue">优秀毕业论文</b>

		  <br/>就职于西安浦发银行<br>信息科技岗

			<br/>

			  <b>&nbsp;</b>

			</p>
</span>
        </div>

     </div>

     

	 <div class="col-xs-3 col-md-2 col-lg-2 text-center">

        <img class="img-circle img-responsive center-block" src="uploads/2018/05/lc.jpg" />

        <div class="member-despt">
<span style="white-space:nowrap" >
          <b>刘成</b>

          <p>本科生，2020届

		  <br />保送至华中科技大学<br>攻读硕士学位

			<br/>

			  <b>&nbsp;</b>

			  <br/>

			  <b>&nbsp;</b>

			</p>
</span>
        </div>

	  </div>

	  

	  <div class="col-xs-3 col-md-2 col-lg-2 text-center">

        <img class="img-circle img-responsive" src="uploads/2018/05/lyw.png" />

        <div class="member-despt">
<span style="white-space:nowrap" >
          <b>李雅文</b>

          <p>研究生，2019届

          <br />

          <b style="color:blue">优秀毕业研究生</b>

			  <br /><span style="white-space:nowrap;">就职于深圳康佳公司</span>	

			<br/>

			  <b>&nbsp;</b>

			  <br/>

			  <b>&nbsp;</b>

			</p>
</span>
        </div>

      </div>

	  

	  <div class="col-xs-3 col-md-2 col-lg-2 text-center">

        <img class="img-circle img-responsive" src="uploads/2018/05/lx.png" />

        <div class="member-despt">
<span style="white-space:nowrap" >
          <b>李鑫</b>

          <p>本科生，2019届

          <br />四川大学<br>攻读硕士学位

			<br/>

			  <b>&nbsp;</b>

			  <br/>

			  <b>&nbsp;</b>	

			</p>
</span>
        </div>

      </div>

      

	  <div class="col-xs-3 col-md-2 col-lg-2 text-center">

        <img class="img-circle img-responsive" src="uploads/2018/05/qxn.png" />

        <div class="member-despt">
<span style="white-space:nowrap" >
          <b>齐晓宁</b>

          <p>本科生，2019届

          <br />

          <b style="color:blue">优秀本科毕业生</b>

		  <br/><b style="color:blue">优秀毕业论文</b>

          <br />保送至中科院计算所<br>攻读硕士学位

			</p>
</span>
        </div>

      </div>

      

	  <div class="col-xs-3 col-md-2 col-lg-2 text-center">

        <img class="img-circle" src="uploads/2018/05/xh.png" />

        <div class="member-despt">
<span style="white-space:nowrap" >
          <b>徐航</b>

          <p>本科生，2018届

          <br>保送至<br>北京航空航天大学<br>攻读硕士学位

			  <br/>

		  <b>&nbsp;</b>



			</p>
</span>
        </div>

      </div>

      

	  <div class="col-xs-3 col-md-2 col-lg-2 text-center">

        <img class="img-circle img-responsive center-block" src="uploads/2018/05/slq.png" />

        <div class="member-despt">
<span style="white-space:nowrap" >
          <b>沈乐棋</b>

		  <p>本科生，2018届

          <br />保送至华中科技大学<br>攻读硕士学位

			<br/>

			  <b>&nbsp;</b>

			  <br/>

			  <b>&nbsp;</b>

			</p>
</span>
        </div>

      </div>

      

	  <div class="col-xs-3 col-md-2 col-lg-2 text-center">

        <img class="img-circle img-responsive center-block" src="uploads/2018/05/pmm.png" />

        <div>
<span style="white-space:nowrap" >
          <b>潘苗苗</b>

          <p>本科生，2018届

			  <br /><span style="white-space:nowrap;">就职于北京链家公司</span>

			<br/>

			  <b>&nbsp;</b>

			  <br/>

			  <b>&nbsp;</b>

			  <br/>

			  <b>&nbsp;</b>

			</p>
</span>
        </div>

      </div>

      

	  <div class="col-xs-3 col-md-2 col-lg-2 text-center">

        <img class="img-circle img-responsive center-block" src="uploads/2018/05/shx.jpg" />

        <div class="member-despt">
<span style="white-space:nowrap" >
          <b>尚海星</b>

          <p>本科生，2017届

          <br />保送至西安交通大学<br>攻读硕士学位

			<br/>

			  <b>&nbsp;</b>

			  <br/>

			  <b>&nbsp;</b>

			</p>
</span>
        </div>

      </div>

      

	  <div class="col-xs-3 col-md-2 col-lg-2 text-center">

        <img class="img-circle img-responsive center-block" src="uploads/2018/05/lk.png" />

        <div class="member-despt">
<span style="white-space:nowrap" >
          <b>廖康</b>

          <p>本科生，2017届

          <br />保送至北京交通大学<br>攻读硕士学位

			<br/>

			  <b>&nbsp;</b>

			  <br/>

			  <b>&nbsp;</b>

			</p>
</span>
        </div>

      </div>

      

	  <div class="col-xs-3 col-md-2 col-lg-2 text-center">

        <img class="img-circle img-responsive center-block" src="uploads/2018/05/sy.jpg" />

        <div class="member-despt">
<span style="white-space:nowrap" >
          <b>苏艺</b>

          <p>本科生，2016届

          <br />

          <b style="color:blue">优秀本科毕业生</b>

          <br />保送至天津大学<br>攻读硕士学位

			<br/>

			  <b>&nbsp;</b>

			</p>
</span>
        </div>

      </div>

      

	  <div class="col-xs-3 col-md-2 col-lg-2 text-center">

        <img class="img-circle img-responsive center-block" src="uploads/2018/05/lpp.jpg" >

        <div class="member-despt">
<span style="white-space:nowrap" >
          <b>李鹏鹏</b>

          <p>本科生，2016届

			  <br><span style="white-space:nowrap;">就职于广州酷狗公司</span>

			<br/>

			  <b>&nbsp;</b>

			  <br/>

			  <b>&nbsp;</b>

			  <br/>

			  <b>&nbsp;</b>

			</p>
</span>
        </div>

      </div>

      

	  <div class="col-xs-3 col-md-2 col-lg-2 text-center">

        <img class="img-circle img-responsive center-block" src="uploads/2018/05/lyx.jpg"  >

        <div class="member-despt">
<span style="white-space:nowrap" >
          <b>刘亚雄</b>

          <p>本科生，2016届

			  <br /><span style="white-space:nowrap;">就职于北京华为公司</span>

			<br/>

			  <b>&nbsp;</b>

			  <br/>

			  <b>&nbsp;</b>

			  <br/>

			  <b>&nbsp;</b>

			</p>
</span>
        </div>

      </div>

      

	  <div class="col-xs-3 col-md-2 col-lg-2 text-center">

        <img class="img-circle img-responsive center-block" src="uploads/2018/05/zx.png" >

        <div class="member-despt">
<span style="white-space:nowrap" >
          <b>周鑫</b>

          <p>本科生，2015届

          <br />

		  <b style="color:blue">优秀毕业论文</b>

          <br />保送至西北工业大学<br>攻读硕士学位

			<br/>

			  <b>&nbsp;</b>

			</p>
</span>
        </div>

      </div>

    </div>

    

		<hr class="simple" style="border:1px solid #2196F3;" />

    <div>

      <h1>项目</h1>

    </div>

	  <ul class="list-group">

      <li class="list-group-item small">[1] 国家自然科学基金面上项目 （2020.1-2023.12，主持）</li>

      <li class="list-group-item small">[2] 国家自然科学基金青年项目 (2016.1-2018.12，主持）</li>

	  <li class="list-group-item small">[3] 陕西省重点研发计划（2021.1-2022.12，主持）</li>

	  <li class="list-group-item small">[4] 陕西省重点研发计划（2018.1-2019.12，主持）</li>

      <li class="list-group-item small">[5] 陕西省自然科学基金青年项目（2015.1-2016.12，主持）</li>

	  <li class="list-group-item small">[6] 空天地海一体化大数据国家工程实验室开放课题（2020.1-2021.12，主持）</li>

	  <li class="list-group-item small">[7] 中央高校基本业务费专项资金一般项目（2020.1-2021.12，主持）</li>

      <li class="list-group-item small">[8] 中央高校基本科研业务费专项资金重点项目（2017.1-2019.12，主持）</li>

      <li class="list-group-item small">[9] 中央高校基本科研业务费专项资金一般项目 (2015.1-2016.12，主持）</li>

      <li class="list-group-item small">[10] 陕西师范大学实验室建设基金项目 （2014.1-2016.12，主持）</li>

      <li class="list-group-item small">[11] 陕西师范大学科研启动基金项目 （2014.1-2016.12，主持）</li>

    </ul>



           <!--New Post1-->

   



<div class="card card-horizontal">

      <div class="card-body">

        <div class="card-horizontal-left">

          <div class="card-category">All-in-focus synthetic aperture imaging using generative adversarial network-based semantic inpainting</div>

          <div class="card-excerpt">

            <p>Occlusions handling poses a significant challenge to many computer vision and pattern recognition applications. Recently, Synthetic Aperture Imaging (SAI), which uses more than two cameras, is widely applied to reconstruct occluded objects in complex scenes. However, it usually fails in cases of heavy occlusions, in particular, when the occluded information is not captured by any of the camera views. Hence, it is a challenging task to generate a realistic all-in-focus synthetic aperture image which shows a completely occluded object. In this paper, semantic inpainting using a Generative Adversarial Network (GAN) is proposed to address the above-mentioned problem. The proposed method first computes a synthetic aperture image of the occluded objects using a labeling method, and an alpha matte of the partially occluded objects. Then, it uses energy minimization to reconstruct the background by focusing on the background depth of each camera. Finally, the occluded regions of the synthesized image are semantically inpainted using a GAN and the results are composited with the reconstructed background to generate a realistic all-in-focus image. 

</p>

          </div>

        </div>

        <div class="card-horizontal-right">

          <img src="uploads/2018/paper/All-in-focus.jpg" />

        </div>

      </div>

    </div>

<!--New Post1-->

 <div class="card card-horizontal">

      <div class="card-body">

        <div class="card-horizontal-left">

          <div class="card-category">Alzheimer's disease diagnosis based on long-range dependency mechanism using convolutional neural network</div>

          <div class="card-excerpt">

            <p>Being able to collect rich morphological information of brain, structural magnetic resonance

imaging (MRI) is popularly applied to computer-aided diagnosis of Alzheimer’s disease

(AD). Conventional methods for AD diagnosis are labor-intensive and typically depend on a

substantial amount of hand-crafted features. In this paper, we propose a novel framework of

convolutional neural network that aims at identifying AD or normal control, and mild cognitive impairment or normal control. The centerpiece of our method are pseudo-3D block

and expanded global context block which are integrated into residual block of backbone in

a cascaded manner. 

</p>

          </div>

        </div>

        <div class="card-horizontal-right">

          <img src="uploads/2018/paper/AlzheimerCNN.jpg" />

        </div>

      </div>

    </div>

	<!-- POST 0 -->

    <div class="card card-horizontal">

      <div class="card-body">

        <div class="card-horizontal-left">

          <div class="card-category">MDEAN: Multi-View Disparity Estimation with an Asymmetric Network</div>

          <div class="card-excerpt">

            <p>In recent years, disparity estimation of a scene based on deep learning methods has been extensively studied and significant progress has been made. 

			Motivated by the results of traditional methods that multi-view methods are more accurate than monocular methods,especially for scenes that are textureless and have thin structures, in this paper, we present MDEAN, a new deep convolutional neural network to estimate disparity using multi-view images with an asymmetric encoder–decoder network structure.</p>

          </div>

        </div>

        <div class="card-horizontal-right">

          <img src="uploads/2018/05/WDQ_CA.png" />

        </div>

      </div>

    </div>

	 <!-- POST 1 -->

    <div class="card card-horizontal">

      <div class="card-body">

        <div class="card-horizontal-left">

          <div class="card-category">Face Recognition via Deep Learning Using Data Augmentation Based on Orthogonal Experiments</div>

          <div class="card-excerpt">

            <p>Recently, many face recognition algorithms via deep learning have achieved promising results with large-scale labeled samples. However, due to the difficulties of collecting samples, 

			face recognition using convolutional neural networks (CNNs) for daily attendance taking remains a challenging problem. In this project, we address 

			this problem using data augmentation through geometric transformation, image brightness changes, and the application of 

			different filter operations. In addition, we determine the best data augmentation method based on orthogonal experiments.</p>

          </div>

        </div>

        <div class="card-horizontal-right">

          <img src="uploads/2018/05/XH_CA.png" />

        </div>

      </div>

    </div>

    <!-- POST 2 -->

    <div class="card card-horizontal">

      <div class="card-body">

        <div class="card-horizontal-left">

          <div class="card-category">Human trajectory prediction in crowded scene using social-affinity Long Short-Term

          Memory</div>

          <div class="card-excerpt">

            <p>Object tracking in crowded spaces is a challenging but very important task in computer vision applications. However,

            due to interactions among large-scale pedestrians and common social rules, predicting the complex human mobility in a

            crowded scene becomes difficult. We propose a novel human trajectory prediction model in a crowded scene called the

            social-affinity LSTM model. Our model can learn general human mobility patterns and predict individual’ s trajectories

            based on their past positions, in particular, with the influence of their neighbors in the Social Affinity Map

            (SAM).</p>

          </div>

        </div>

        <div class="card-horizontal-right">

          <img src="uploads/2018/05/QXN_LSTM.jpg" />

        </div>

      </div>

    </div>

    <!-- POST 3 -->

    <div class="card card-horizontal">

      <div class="card-body">

        <div class="card-horizontal-left">

          <div class="card-category">Focus Measure for Synthetic Aperture Imaging Using a Deep Convolutional Network</div>

          <div class="card-excerpt">

            <p>Synthetic aperture imaging is a technique that mimics a camera with a large virtual convex lens with a camera array.

            Objects on the focal plane will be sharp and off the focal plane blurry in the synthesized image, which is the most

            important effect that can be achieved with synthetic aperture imaging. Unlike conventional focus estimation methods

            which pick the focal plane with the minimum variance computed by the variance of corresponding pixels captured by

            different views in a camera array, our method automatically determines if the synthetic aperture image is focused or

            not from one single image of a scene without other views using a deep neural network. In particular, our method can be

            applied to automatically select the focal plane for synthetic aperture images.</p>

          </div>

        </div>

        <div class="card-horizontal-right">

          <img src="uploads/2018/05/HL_SAI.jpg" />

        </div>

      </div>

    </div>

    <!-- POST 4 -->

    <div class="card card-horizontal">

      <div class="card-body">

        <div class="card-horizontal-left">

          <div class="card-category">All-In-Focus Synthetic Aperture Imaging Using Image Matting</div>

          <div class="card-excerpt">

            <p>Removing the blurriness caused by defocusing in synthetic aperture images to achieve an all-in-focus “seeing

            through” image is a challenging research problem. In this project, we propose a novel method to improve the image

            quality of synthetic aperture imaging using image matting via energy minimization by estimating the foreground and the

            background. We show that both the occluded objects and the background can be combined using our method to create a

            sharp synthetic aperture image</p>

          </div>

        </div>

        <div class="card-horizontal-right">

          <img src="uploads/2018/05/ZP_SAI.jpg" />

        </div>

      </div>

    </div>

    <!-- POST 5 -->

    <div class="card card-horizontal">

      <div class="card-body">

        <div class="card-horizontal-left">

          <div class="card-category">Occluded-Object 3D Reconstruction Using Camera Array Synthetic Aperture Imaging</div>

          <div class="card-excerpt">

            <p>Object reconstruction is a technique which aims to recover the shape and appearance information of objects. Although

            great progress in object reconstruction has been made over the past few years, object reconstruction in occlusion

            situations remains a challenging problem. We propose a novel method to reconstruct occluded objects based on synthetic

            aperture imaging, our method uses the characteristics of synthetic aperture imaging that can effectively reduce the

            influence of occlusion to reconstruct the scene with occlusion.</p>

          </div>

        </div>

        <div class="card-horizontal-right">

          <img src="uploads/2018/05/LYW_SAI.png" />

        </div>

      </div>

    </div>

    <!-- POST 6 -->

    <div class="card card-horizontal">

      <div class="card-body">

        <div class="card-horizontal-left">

          <div class="card-category">Camera array</div>

          <div class="card-excerpt">

            <p>In this project, we develop two different camera array systems. One of the camera array consists of 10 consumer

            grade Axis 211W Ethernet network cameras. Each Axis 211W camera captures images at a resolution of 640*480, which are

            stored by a central computer. The distance between two adjacent cameras is approximately 32cm. Since there are 10

            cameras in the array, thus, the whole camera array simulates a virtual aperture with a size of approximately 3.0 m. The

            other camera array consists of 12 Point Grey Research Flea2 color cameras with a resolution of 1024*768. Each pair of

            cameras is connected to a single computer. The distance between two adjacent cameras is approximately 23 cm and the

            array simulates a camera with a virtual aperture of approximately 2.5 m.</p>

          </div>

        </div>

        <div class="card-horizontal-right">

          <img src="uploads/2018/05/ZP_CA.png" />

        </div>

      </div>

    </div>

    <!-- POST 7 -->

    <div class="card card-horizontal">

      <div class="card-body">

        <div class="card-horizontal-left">

          <div class="card-category">Synthetic aperture detection</div>

          <div class="card-excerpt">

            <p>In this project, we have developed a novel multi-object detection method using multiple cameras. Unlike conventional

            multi-camera object detection methods, our method detects multiple objects using a linear camera array. The array can

            stream different views of the environment and can be easily reconfigured for a scene compared with the overhead

            surround configuration. Using the proposed method, the synthesized results can provide not only views of significantly

            occluded objects but also the ability of focusing on the target while blurring objects that are not of interest. Our

            method does not need to reconstruct the 3D structure of the scene, can accommodate dynamic background, is able to

            detect objects at any depth by using a new synthetic aperture imaging method based on a simple shift transformation,

            and can see through occluders.</p>

          </div>

        </div>

        <div class="card-horizontal-right">

          <img src="uploads/2018/05/ZP_SAD.png" />

        </div>

      </div>

    </div>

    <!-- POST 8 -->

    <div class="card card-horizontal">

      <div class="card-body">

        <div class="card-horizontal-left">

          <div class="card-category">Detection using two camera arrays</div>

          <div class="card-excerpt">

            <p>In this project, we propose a novel multi-object detection method using multiple camera arrays. Our detection

            algorithm calibrates two camera arrays based on a simple shift transformation. And also, the object can be shown in two

            different sides of the view from each camera array. Compare with one camera array synthetic aperture detection, our

            method can handle the small depth difference between the objects. What is more, instead of focusing on parallel plane,

            our method can focus on tilted plane. The experimental results show that the proposed method has a good performance and

            can successfully detect the objects within a small depth range.</p>

          </div>

        </div>

        <div class="card-horizontal-right">

          <img src="uploads/2018/05/ZP_DCA.png" />

        </div>

      </div>

    </div>

    <!-- POST 9 -->

    <div class="card card-horizontal">

      <div class="card-body">

        <div class="card-horizontal-left">

          <div class="card-category">Synthetic aperture image quality assessment</div>

          <div class="card-excerpt">

            <p>In this project, according to the designed experiment, we systematically evaluated the quality of synthetic aperture

            image by several widely used image quality metrics. And, determine the performance of these metrics on synthetic

            aperture image. Then, using some good performance metrics on autofocusing to determine on which focal plane is hidden

            object.</p>

          </div>

        </div>

        <div class="card-horizontal-right">

          <img src="uploads/2018/05/ZP_SAA.png" />

        </div>

      </div>

    </div>

    <!-- POST 10 -->

    <div class="card card-horizontal">

      <div class="card-body">

        <div class="card-horizontal-left">

          <div class="card-category">Convolutional Neural Networks for Class Attendance</div>

          <div class="card-excerpt">

            <p>Conventionally, students attendance records are taken manually by teachers through roll calling in the class. It is

            time-consuming and prone to errors. Moreover, records of attendance are difficult to handle and preserve for the

            longterm. We propose a more conveniently method of attendance statistics, which achieved through the Convolutional

            Neural Network (CNN).</p>

          </div>

        </div>

        <div class="card-horizontal-right">

          <img src="uploads/2018/05/HX_CA.jpg" />

        </div>

      </div>

    </div></div>

  </body>

</html>

