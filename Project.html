<!DOCTYPE html>
<html lang="en-US">
  <head>
      <meta charset="UTF-8" />
    <meta name="generator"
    content="HTML Tidy for HTML5 (experimental) for Windows https://github.com/w3c/tidy-html5/tree/c63cc39" />
    <title>智能视觉实验室</title>
    <!-- META TAGS -->
    
    <!-- CSS FILES -->
    <link href="https://cdn.staticfile.org/twitter-bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet" />
    <link href="css/fontawesome.css" rel="stylesheet" type="text/css" />
    <link href="css/slick.css" rel="stylesheet" type="text/css" />
    <link href="css/style.css" rel="stylesheet" type="text/css" />
  </head>
  <body>
  <!-- READING POSITION INDICATOR -->
  <progress value="0" id="eskimo-progress-bar"></progress>
  <div class="container">
  <!-- SIDEBAR -->
    <img src="images/Peterlogo.png" /> 
  <!--菜单栏-->
  <nav class="navbar navbar-default" role="navigation">
    <ul class="nav navbar-nav">
      <li>
        <a href="index.html">首页</a>
      </li>
      <li>
        <a href="Project.html">项目</a>
      </li>
      <li>
        <a href="Member.html">小组成员</a>
      </li>
      <li>
        <a href="Result.html">研究成果</a>
      </li>
      <li>
        <a href="Contact.html">联系我们</a>
      </li>
    </ul>
  </nav>
  <!-- POST 1 -->
  <div class="card card-horizontal">
    <div class="card-body">
      <div class="card-horizontal-left">
        <div class="card-category">Human trajectory prediction in crowded scene using social-affinity Long Short-Term Memory</div>
        <div class="card-excerpt">
          <p>Object tracking in crowded spaces is a challenging but very important task in computer vision applications. However,
          due to interactions among large-scale pedestrians and common social rules, predicting the complex human mobility in a
          crowded scene becomes difficult. We propose a novel human trajectory prediction model in a crowded scene called the
          social-affinity LSTM model. Our model can learn general human mobility patterns and predict individual’ s trajectories
          based on their past positions, in particular, with the influence of their neighbors in the Social Affinity Map (SAM).</p>
        </div>
      </div>
      <div class="card-horizontal-right">
        <img src="uploads/2018/05/LSTM.jpg" />
      </div>
    </div>
  </div>
  <!-- POST 2 -->
  <div class="card card-horizontal">
    <div class="card-body">
      <div class="card-horizontal-left">
        <div class="card-category">Focus Measure for Synthetic Aperture Imaging Using a Deep Convolutional Network</div>
        <div class="card-excerpt">
          <p>Synthetic aperture imaging is a technique that mimics a camera with a large virtual convex lens with a camera array.
          Objects on the focal plane will be sharp and off the focal plane blurry in the synthesized image, which is the most
          important effect that can be achieved with synthetic aperture imaging. Unlike conventional focus estimation methods which
          pick the focal plane with the minimum variance computed by the variance of corresponding pixels captured by different
          views in a camera array, our method automatically determines if the synthetic aperture image is focused or not from one
          single image of a scene without other views using a deep neural network. In particular, our method can be applied to
          automatically select the focal plane for synthetic aperture images.</p>
        </div>
      </div>
      <div class="card-horizontal-right">
        <img src="uploads/2018/05/HL.jpg" />
      </div>
    </div>
  </div>
  <!-- POST 3 -->
  <div class="card card-horizontal">
    <div class="card-body">
      <div class="card-horizontal-left">
        <div class="card-category">All-In-Focus Synthetic Aperture Imaging Using Image Matting</div>
        <div class="card-excerpt">
          <p>Removing the blurriness caused by defocusing in synthetic aperture images to achieve an all-in-focus “seeing through”
          image is a challenging research problem. In this project, we propose a novel method to improve the image quality of
          synthetic aperture imaging using image matting via energy minimization by estimating the foreground and the background.
          We show that both the occluded objects and the background can be combined using our method to create a sharp synthetic
          aperture image</p>
        </div>
      </div>
      <div class="card-horizontal-right">
        <img src="uploads/2018/05/ZP.jpg" />
      </div>
    </div>
  </div>
  <!-- POST 4 -->
  <div class="card card-horizontal">
    <div class="card-body">
      <div class="card-horizontal-left">
        <div class="card-category">Occluded-Object 3D Reconstruction Using Camera Array Synthetic Aperture Imaging</div>
        <div class="card-excerpt">
          <p>Object reconstruction is a technique which aims to recover the shape and appearance information of objects. Although
          great progress in object reconstruction has been made over the past few years, object reconstruction in occlusion
          situations remains a challenging problem. We propose a novel method to reconstruct occluded objects based on synthetic
          aperture imaging, our method uses the characteristics of synthetic aperture imaging that can effectively reduce the
          influence of occlusion to reconstruct the scene with occlusion.</p>
        </div>
      </div>
      <div class="card-horizontal-right">
        <img src="uploads/2018/05/LYWP.png" />
      </div>
    </div>
  </div>
  <!-- POST 6 -->
  <div class="card card-horizontal">
    <div class="card-body">
      <div class="card-horizontal-left">
        <div class="card-category">Synthetic aperture detection</div>
        <div class="card-excerpt">
          <p>In this project, we have developed a novel multi-object detection method using multiple cameras. Unlike conventional
          multi-camera object detection methods, our method detects multiple objects using a linear camera array. The array can
          stream different views of the environment and can be easily reconfigured for a scene compared with the overhead surround
          configuration. Using the proposed method, the synthesized results can provide not only views of significantly occluded
          objects but also the ability of focusing on the target while blurring objects that are not of interest. Our method does
          not need to reconstruct the 3D structure of the scene, can accommodate dynamic background, is able to detect objects at
          any depth by using a new synthetic aperture imaging method based on a simple shift transformation, and can see through
          occluders.</p>
        </div>
      </div>
      <div class="card-horizontal-right">
        <img src="uploads/2018/05/abc.png" />
      </div>
    </div>
  </div>
  <!-- POST 7 -->
  <div class="card card-horizontal">
    <div class="card-body">
      <div class="card-horizontal-left">
        <div class="card-category">Detection using two camera arrays</div>
        <div class="card-excerpt">
          <p>In this project, we propose a novel multi-object detection method using multiple camera arrays. Our detection
          algorithm calibrates two camera arrays based on a simple shift transformation. And also, the object can be shown in two
          different sides of the view from each camera array. Compare with one camera array synthetic aperture detection, our
          method can handle the small depth difference between the objects. What is more, instead of focusing on parallel plane,
          our method can focus on tilted plane. The experimental results show that the proposed method has a good performance and
          can successfully detect the objects within a small depth range.</p>
        </div>
      </div>
      <div class="card-horizontal-right">
        <img src="uploads/2018/05/web5.png" />
      </div>
    </div>
  </div>
  <!-- POST 8 -->
  <div class="card card-horizontal">
    <div class="card-body">
      <div class="card-horizontal-left">
        <div class="card-category">Synthetic aperture image quality assessment</div>
        <div class="card-excerpt">
          <p>In this project, according to the designed experiment, we systematically evaluated the quality of synthetic aperture
          image by several widely used image quality metrics. And, determine the performance of these metrics on synthetic aperture
          image. Then, using some good performance metrics on autofocusing to determine on which focal plane is hidden object.</p>
        </div>
      </div>
      <div class="card-horizontal-right">
        <img src="uploads/2018/05/pinggu.png" />
      </div>
    </div>
  </div>
  <!-- POST 9 -->
  <div class="card card-horizontal">
    <div class="card-body">
      <div class="card-horizontal-left">
        <div class="card-category">Convolutional Neural Networks for Class Attendance</div>
        <div class="card-excerpt">
          <p>Conventionally, students attendance records are taken manually by teachers through roll calling in the class. It is
          time-consuming and prone to errors. Moreover, records of attendance are difficult to handle and preserve for the
          longterm. We propose a more conveniently method of attendance statistics, which achieved through the Convolutional Neural
          Network (CNN).</p>
        </div>
      </div>
      <div class="card-horizontal-right">
        <img src="uploads/2018/05/HXP.jpg" />
      </div>
    </div>
  </div>
  <!-- CAROUSEL --></div>
  <!-- JS FILES -->
  <script src="js/jquery-3.3.1.min.js"></script> 
  <script src="js/bootstrap.min.js"></script></body>
</html>
